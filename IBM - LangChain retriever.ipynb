{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Develop a Retriever to Fetch Document Segments Based on Queries**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **40** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are working on a project that involves processing a large collection of text documents, such as research papers, legal documents, or customer service logs. Your task is to develop a system that can quickly retrieve the most relevant segments of text based on a user's query. Traditional keyword-based search methods might not be sufficient, as they often fail to capture the nuanced meanings and contexts within the documents. To address this challenge, you can use different types of retrievers based on LangChain.\n",
    "\n",
    "Using retrievers is crucial for several reasons:\n",
    "\n",
    "- Efficiency: Retrievers enable fast and efficient retrieval of relevant information from large datasets, saving time and computational resources.\n",
    "- Accuracy: By leveraging advanced retrieval techniques, these tools can provide more accurate and contextually relevant results compared to traditional search methods.\n",
    "- Versatility: Different retrievers can be tailored to specific use cases, making them adaptable to various types of text data and query requirements.\n",
    "- Context awareness: Some retrievers, like the Parent Document Retriever, can consider the broader context of the document, enhancing the relevance of the retrieved segments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/EUODrOFxvSSNL935zpwh9A/retriever.png\" width=\"50%\" alt=\"retriever\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will learn how to use various retrievers to efficiently extract relevant document segments from text using LangChain. \n",
    "You will learn about four types of retrievers: `Vector Store-backed Retriever`, `Multi-Query Retriever`, `Self-Querying Retriever`, and `Parent Document Retriever`. You will also learn the differences between these retrievers and understand the appropriate situations in which to use each one. By the end of this lab, you will be equipped with the skills to implement and utilize these retrievers in your projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-required-libraries\">Installing required libraries</a></li>\n",
    "            <li><a href=\"#Defining-helper-functions\">Defining helper functions</a>\n",
    "                <ol>\n",
    "                    <li><a href=\"#Build-LLM\">Build LLM</a></li>\n",
    "                    <li><a href=\"#Text-splitter\">Text splitter</a></li>\n",
    "                    <li><a href=\"#Embedding-model\">Embedding model</a></li>\n",
    "                </ol>\n",
    "            </li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Retrievers\">Retrievers</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Vector-Store-Backed-Retriever\">Vector Store-Backed Retriever</a></li>\n",
    "            <li><a href=\"#Multi-Query-Retriever\">Multi-Query Retriever</a></li>\n",
    "            <li><a href=\"#Self-Querying-Retriever\">Self-Querying Retriever</a></li>\n",
    "            <li><a href=\"#Parent-Document-Retriever\">Parent Document Retriever</a></li>\n",
    "        </ol>\n",
    "\n",
    "   \n",
    "            \n",
    "<li><a href=\"#Exercises\">Exercises</a>\n",
    "<ol>\n",
    "<li><a href=\"#Retrieve-top-2-results-using-vector-store-backed-retriever\">Retrieve top 2 results using vector store-backed retriever</a></li>\n",
    "<li><a href=\"#Self-Querying-Retriever-for-a-query\">Self querying retriever for a query</a></li>\n",
    "</ol>\n",
    "</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "- Use various types of retrievers to efficiently extract relevant document segments from text, leveraging LangChain's capabilities.\n",
    "- Apply the Vector Store-backed Retriever to solve problems involving semantic similarity and relevance in large text datasets.\n",
    "- Utilize the Multi-Query Retriever to address situations where multiple query variations are needed to capture comprehensive results.\n",
    "- Implement the Self-Querying Retriever to automatically generate and refine queries, enhancing the accuracy of information retrieval.\n",
    "- Employ the Parent Document Retriever to maintain context and relevance by considering the broader context of the parent document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, you will use the following libraries:\n",
    "\n",
    "*   [`ibm-watson-ai`](https://ibm.github.io/watsonx-ai-python-sdk/index.html) for using LLMs from IBM's watsonx.ai.\n",
    "*   [`langchain`, `langchain-ibm`, `langchain-community`](https://www.langchain.com/) for using relevant features from LangChain.\n",
    "*   [`pypdf`](https://pypi.org/project/pypdf/)is an open-source pure Python PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files.\n",
    "*   [`chromadb`](https://www.trychroma.com/) is an open-source vector database used to store embeddings.\n",
    "*   [`lark`](https://pypi.org/project/lark/) is a general-purpose parsing library for Python. It is necessary for a Self-Querying Retriever.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing required libraries\n",
    "\n",
    "The following required libraries are __not__ preinstalled in the Skills Network Labs environment. __You must run the following cell__ to install them:\n",
    "\n",
    "**Note:** The version is being pinned here to specify the version. It's recommended that you do this as well. Even if the library is updated in the future, the installed library could still support this lab work.\n",
    "\n",
    "This might take approximately 1-2 minutes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.12/site-packages (from lomond->ibm-watsonx-ai==1.1.2) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.1) (1.3.1)\n",
      "Successfully installed langchain-ibm-0.1.11\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.1) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/jupyterlab/.local/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (0.6.1)\n",
      "Successfully installed pypdf-4.3.1\n",
      "Successfully installed lark-1.1.9\n"
     ]
    }
   ],
   "source": [
    "# Please restart the kernel and run all cells after executing this cell.\n",
    "!pip install --user \"ibm-watsonx-ai==1.1.2\" | tail -n 1\n",
    "!pip install --user \"langchain==0.2.1\" | tail -n 1\n",
    "!pip install --user \"langchain-ibm==0.1.11\" | tail -n 1\n",
    "!pip install --user \"langchain-community==0.2.1\" | tail -n 1\n",
    "!pip install --user \"chromadb==0.4.24\" | tail -n 1\n",
    "!pip install --user \"pypdf==4.3.1\" | tail -n 1\n",
    "!pip install --user \"lark==1.1.9\" | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you install the libraries, restart your kernel. You can do that by clicking the **Restart the kernel** icon.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/QrUNwLZfVySxQ9xvbOJgyQ/restart.png\" width=\"80%\" alt=\"Restart kernel\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions\n",
    "\n",
    "_Use the following code to define some helper functions to reduce the repeat work in the notebook:_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are prerequisite knowledge for understanding the topic of this project—retrievers. These functions include:\n",
    "\n",
    "- Building LLMs\n",
    "- Splitting documents into chunks\n",
    "- Building an embedding model\n",
    "\n",
    "The relevant knowledge and details of these functions have been covered in previous lessons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models.extensions.langchain import WatsonxLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mixtral-8x7b-instruct-v01` is used as the base foundational LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm():\n",
    "    model_id = 'mistralai/mixtral-8x7b-instruct-v01'\n",
    "    \n",
    "    parameters = {\n",
    "        GenParams.MAX_NEW_TOKENS: 256,  # this controls the maximum number of tokens in the generated output\n",
    "        GenParams.TEMPERATURE: 0.5, # this randomness or creativity of the model's responses\n",
    "    }\n",
    "    \n",
    "    credentials = {\n",
    "        \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    project_id = \"skills-network\"\n",
    "    \n",
    "    model = ModelInference(\n",
    "        model_id=model_id,\n",
    "        params=parameters,\n",
    "        credentials=credentials,\n",
    "        project_id=project_id\n",
    "    )\n",
    "    \n",
    "    mixtral_llm = WatsonxLLM(model = model)\n",
    "    return mixtral_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_splitter(data, chunk_size, chunk_overlap):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code demonstrates how to build an embedding model using the `watsonx.ai` package.\n",
    "\n",
    "For this project, the `ibm/slate-125m-english-rtrvr` embedding model is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
    "from langchain_ibm import WatsonxEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watsonx_embedding():\n",
    "    embed_params = {\n",
    "        EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
    "        EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
    "    }\n",
    "    \n",
    "    watsonx_embedding = WatsonxEmbeddings(\n",
    "        model_id=\"ibm/slate-125m-english-rtrvr\",\n",
    "        url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "        project_id=\"skills-network\",\n",
    "        params=embed_params,\n",
    "    )\n",
    "    return watsonx_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrievers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A retriever is an interface designed to return documents based on an unstructured query. Unlike a vector store, which stores and retrieves documents, a retriever's primary function is to find and return relevant documents. While vector stores can serve as the backbone of a retriever, there are various other types of retrievers that can be used as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrievers take a string `query` as input and output a list of `Documents`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store-Backed Retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector store retriever is a type of retriever that utilizes a vector store to fetch documents. It acts as a lightweight wrapper around the vector store class, enabling it to conform to the retriever interface. This retriever leverages the search methods implemented by the vector store, such as similarity search and Maximum Marginal Relevance (MMR), to query texts stored within it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before demonstrating this retriever, you need to load some example text. A `.txt` document has been prepared for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-09-01 06:59:09--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/MZ9z1lm-Ui3YBp3SYWLTAQ/companypolicies.txt\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 15660 (15K) [text/plain]\n",
      "Saving to: ‘companypolicies.txt.2’\n",
      "\n",
      "companypolicies.txt 100%[===================>]  15.29K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-09-01 06:59:09 (73.7 MB/s) - ‘companypolicies.txt.2’ saved [15660/15660]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/MZ9z1lm-Ui3YBp3SYWLTAQ/companypolicies.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `TextLoader` to load the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"companypolicies.txt\")\n",
    "txt_data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at this document. This is a document about different policies in a company.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split `txt_data` into chunks. `chunk_size = 200`, `chunk_overlap = 20` has been set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_txt = text_splitter(txt_data, 200, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the embeddings into a `ChromaDB`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(chunks_txt, watsonx_embedding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple similarity search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a simple similarity search based on the vector database.\n",
    "\n",
    "For this demonstration, the query has been set to \"email policy\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"email policy\"\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the number of retrieval results is four, and they are ranked by similarity level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy aims to maintain a safe, healthy, and productive workplace.'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='will ensure its alignment with evolving legal requirements and best practices.'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Review of Policy: This policy will be reviewed periodically to ensure its alignment with evolving legal requirements and best practices for maintaining a healthy and safe workplace.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify `search kwargs` like `k` to limit the retrieval results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 1})\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MMR retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMR in vector stores is a technique used to balance the relevance and diversity of retrieved results. It selects documents that are both highly relevant to the query and minimally similar to previously selected documents. This approach helps to avoid redundancy and ensures a more comprehensive coverage of different aspects of the query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is showing how to conduct an MMR search in a vector database. You just need to sepecify `search_type=\"mmr\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Employee Referrals: We encourage and appreciate employee referrals as they contribute to building a strong and engaged team.'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content=\"Data Privacy: We are committed to protecting the privacy of candidates' personal information and adhere to all relevant data protection laws and regulations.\"),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='harassment. This organization considers it a collective responsibility to ensure a workplace free from discrimination and harassment, and it is essential that every individual within the organization')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(search_type=\"mmr\")\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity score threshold retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set a retrieval method that defines a similarity score threshold, returning only documents with a score above that threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy aims to maintain a safe, healthy, and productive workplace.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.4}\n",
    ")\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Query Retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance-based vector database retrieval represents queries in high-dimensional space and finds similar embedded documents based on \"distance\". However, retrieval results may vary with subtle changes in query wording or if the embeddings do not accurately capture the data's semantics.\n",
    "\n",
    "The `MultiQueryRetriever` addresses this by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and then takes the unique union of these results to form a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the `MultiQueryRetriever` can potentially overcome some limitations of distance-based retrieval, resulting in a richer and more diverse set of results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following picture shows the difference between retrievers solely based on distance and the Multi-Query Retriever.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/NCZCJ26bp3uKTa0gp8Agwg/multiquery.png\" width=\"40%\" alt=\"multiquery\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the query sentence, `\"I like cats\"`.\n",
    "\n",
    "On the upper side of the picture, you can see a retriever that relies solely on distance. This retriever calculates the distance between the query and the documents in the vector store, returning the document with the closest match.\n",
    "\n",
    "On the lower side, you can see a multi-query retriever. It first uses an LLM to generate multiple queries from different perspectives based on the user's input query. For each generated query, it retrieves relevant documents and then returns the union of these results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PDF document has been prepared to demonstrate this Multi-Query Retriever.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf\")\n",
    "pdf_data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first page of this paper. This paper is talking about the framework LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'page': 1}, page_content='LangChain helps us to unlock the ability to harness the \\nLLM’s immense potential in tasks such as document analysis, \\nchatbot development, code analysis, and countless other \\napplications. Whether your desire is to unlock deeper natural \\nlanguage understanding , enhance data, or circumvent \\nlanguage barriers through translation, LangChain is ready to \\nprovide the tools and programming support you need to do \\nwithout it that it is not only difficult but also fresh for you . Its \\ncore functionalities encompass:  \\n1. Context -Aware Capabilities: LangChain facilitates the \\ndevelopment of applications that are inherently \\ncontext -aware. This means that these applications can \\nconnect to a language model and draw from various \\nsources of context, such as prompt instructions, a  few-\\nshot examples, or existing content, to ground their \\nresponses effectively.  \\n2. Reasoning Abilities: LangChain equips applications \\nwith the capacity to reason effectively. By relying on a \\nlanguage model, these applications can make informed \\ndecisions about how to respond based on the provided \\ncontext and determine the appropriate acti ons to take.  \\nLangChain offers several key value propositions:  \\nModular Components: It provides abstractions that \\nsimplify working with language models, along with a \\ncomprehensive collection of implementations for each \\nabstraction. These components are designed to be modular \\nand user -friendly, making them useful whethe r you are \\nutilizing the entire LangChain framework or not.  \\nOff-the-Shelf Chains: LangChain offers pre -configured \\nchains, which are structured assemblies of components \\ntailored to accomplish specific high -level tasks. These pre -\\ndefined chains streamline the initial setup process and serve as \\nan ideal starting point  for your projects. The MindGuide Bot \\nuses below components from LangChain . \\nA. ChatModel  \\nWithin LangChain, a ChatModel is a specific kind of \\nlanguage model crafted to manage conversational \\ninteractions. Unlike traditional language models that take one \\nstring as input and generate a single string as output, \\nChatModels operate with a list of mes sages as input, \\ngenerating a message as output.  \\nEach message in the list has two parts: the content and the \\nrole. The content is the actual text or substance of the message, \\nwhile the role denotes the role or source of the message (such \\nas \"User,\" \"Assistant,\" \"System,\" etc.).  \\nThis approach with ChatModels opens the door to more \\ndynamic and interactive conversations with the language \\nmodel. It empowers the creation of chatbot applications, \\ncustomer support systems, or any other application involving \\nmulti -turn conversations. We utilized the ChatOpenAI \\nChatModel to create MindGuide chatbots specifically \\ndesigned to function as mental health therapists. In our \\ninteraction with OpenAI, we opted for an OpenAI API key to \\nengage with the ChatGpt3 turbo model and utilized a \\ntemperature value of 0.5. The steps to create an OpenAI API \\nkey are outlined [ 9].  B. Message  \\nIn the context of LangChain, messages  [10] refer to a list of \\nmessages that are used as input when interacting with a \\nChatModel. Each message in the list represents a specific turn \\nor exchange in a conversation.  Each message in the messages \\nlist typically consists of two components:  \\n• content: This represents the actual text or content of \\nthe message. It can be a user query, a system \\ninstruction, or any other relevant information.  \\n• role: This represents the role or source of the \\nmessage. It defines who is speaking or generating \\nthe message. Common roles include \"User\", \\n\"Assistant\", \"System\", or any other custom role you \\ndefine . \\nThe chat model interface is based around messages rather \\nthan raw text. The types of messages supported in LangChain \\nare Systen Message, HumanMessage, and AIMessage . \\nSystemMessage  is the ChatMessage coming from the system  \\nin its LangChain template  as illustrated in Figure 1. Human \\nMessage  is a ChatMessage coming from a human/user.  \\nAIMessage is a ChatMessage  coming from an AI/assistant as \\nillustrated in Figure 2 .  \\n \\n                   Figure 1. A System Message illustration   You are a compassionate and experienced mental \\nhealth therapist with a proven track record of \\nhelping patients overcome anxiety and other mental \\nhealth challenges. Your primary objective is to \\nsupport the patient in addressing their concerns \\nand guiding th em towards positive change. In this \\ninteractive therapy session, you will engage with \\nthe patient by asking open -ended questions, \\nactively listening to their responses, and providing \\nempathetic feedback. Your approach is \\ncollaborative, and you strive to cr eate a safe and \\nnon-judgmental space for the patient to share their \\nthoughts and feelings.  \\nAs the patient shares their struggles, you will \\nprovide insightful guidance and evidence -based \\nstrategies tailored to their unique needs. You may \\nalso offer practical exercises or resources to help \\nthem manage their symptoms and improve their \\nmental wellbe ing. When necessary, you will gently \\nredirect the conversation back to the patient\\'s \\nprimary concerns related to anxiety, mental health, \\nor family issues. This ensures that each session is \\nproductive and focused on addressing the most \\npressing issues. Thro ughout the session, you \\nremain mindful of the patient\\'s emotional state and \\nadjust your approach accordingly.  \\nYou recognize that everyone\\'s journey is \\ndifferent, and that progress can be incremental.  \\nBy building trust and fostering a strong \\ntherapeutic relationship, you empower the patient \\nto take ownership of their growth and development. \\nAt the end of the session, you will summarize key \\npoints from your discussion, highlighting the \\npatient\\'s strength s and areas for improvement.  \\nTogether, you will set achievable goals for future \\nsessions, reinforcing a sense of hope and \\nmotivation. Your ultimate goal is to equip the \\npatient with the tools and skills needed to navigate \\nlife\\'s challenges with confidence and resilience . ')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split document and store the embeddings into a vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionDeleteEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "chunks_pdf = text_splitter(pdf_data, 500, 20)\n",
    "\n",
    "# VectorDB\n",
    "ids = vectordb.get()[\"ids\"]\n",
    "vectordb.delete(ids) # We need to delete existing embeddings from previous documents and then store current document embeddings in.\n",
    "vectordb = Chroma.from_documents(documents=chunks_pdf, embedding=watsonx_embedding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MultiQueryRetriever` function from LangChain is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# query = \"What does the paper say about langchain?\"\n",
    "\n",
    "# retriever = MultiQueryRetriever.from_llm(\n",
    "#     retriever=vectordb.as_retriever(), llm=llm()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set logging for the queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 0, 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf'}, page_content='Additionally, the paper discusses the implementation of \\nStreamlit to enhance the user ex perience and interaction with \\nthe chatbot. Th is novel approach holds great promise for \\nproactive mental health intervention and assistance . \\nKeywords  —Large Language models , LangChain,  Chatbot , \\nPretrained models , Mental health , Mental health support . \\nI. INTRODUCTION  \\nThe issue of mental health is an international situation, \\naffecting people in each particularly developed nations and'),\n",
       " Document(metadata={'page': 0, 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf'}, page_content='the use of contextualized pretrained language models  [4], \\nwhich have garnered substantial attention for their \\neffectiveness in various text processing tasks.  \\nThis paper delves into the application of these recent \\nadvancements in pretrained contextualized large language \\nmodels to introduce MindGuide , an innovative chatbot \\ndesigned to function as a mental health assistant for \\nindividuals in need of guidance and support in these critical'),\n",
       " Document(metadata={'page': 1, 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf'}, page_content='utilizing the entire LangChain framework or not.  \\nOff-the-Shelf Chains: LangChain offers pre -configured \\nchains, which are structured assemblies of components \\ntailored to accomplish specific high -level tasks. These pre -\\ndefined chains streamline the initial setup process and serve as \\nan ideal starting point  for your projects. The MindGuide Bot \\nuses below components from LangChain . \\nA. ChatModel  \\nWithin LangChain, a ChatModel is a specific kind of'),\n",
       " Document(metadata={'page': 1, 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf'}, page_content='• content: This represents the actual text or content of \\nthe message. It can be a user query, a system \\ninstruction, or any other relevant information.  \\n• role: This represents the role or source of the \\nmessage. It defines who is speaking or generating \\nthe message. Common roles include \"User\", \\n\"Assistant\", \"System\", or any other custom role you \\ndefine . \\nThe chat model interface is based around messages rather \\nthan raw text. The types of messages supported in LangChain')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the log results, you can see that the LLM generated three additional queries from different perspectives based on the given query.\n",
    "\n",
    "The returned results are the union of the results from each query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Querying Retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Self-Querying Retriever, as the name suggests, has the ability to query itself. Specifically, given a natural language query, the retriever uses a query-constructing LLM chain to generate a structured query. It then applies this structured query to its underlying vector store. This enables the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but also to extract and apply filters based on the metadata of those documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code demonstrates how to use a Self-Querying Retriever.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from lark import lark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of document pieces have been prepared where the `page_content` contains descriptions of movies, and the `meta_data` includes different attributes for each movie, such as `year`, `rating`, `genre`, and `director`. These attributes are crucial in the Self-Querying Retriever, as the LLM will use the metadata information to apply filters during the retrieval process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can instantiate your retriever. To do this, you'll need to provide some upfront information about the metadata fields that your documents support, as well as a brief description of the document contents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `SelfQueryRetriever`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can actually try using your retriever.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the following cell, you might encounter some errors or blank content. This is because the LLM cannot get the answer at first. Don't worry; if you re-run it several times, you will get the answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parent Document Retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When splitting documents for retrieval, there are often conflicting desires:\n",
    "\n",
    "1. You may want to have small documents so that their embeddings can most accurately reflect their meaning. If the documents are too long, the embeddings can lose meaning.\n",
    "2. You want to have long enough documents so that the context of each chunk is retained.\n",
    "\n",
    "The `ParentDocumentRetriever` strikes that balance by splitting and storing small chunks of data. During retrieval, it first fetches the small chunks but then looks up the parent IDs for those chunks and returns those larger documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.storage import InMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set two splitters. One is with big chunk size (parent) and one is with small chunk size (child)\n",
    "parent_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=20, separator='\\n')\n",
    "child_splitter = CharacterTextSplitter(chunk_size=400, chunk_overlap=20, separator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    collection_name=\"split_parents\", embedding_function=watsonx_embedding()\n",
    ")\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectordb,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(chunks_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the number of large chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(store.yield_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the underlying vector store still retrieves the small chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = vectordb.similarity_search(\"smoking policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, retrieve the relevant large chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"smoking policy\")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "### Retrieve top 2 results using vector store-backed retriever\n",
    "\n",
    "Can you retrieve the top two results for the company policy document for the query \"smoking policy\" using the Vector Store-Backed Retriever?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=chunks_txt, embedding=watsonx_embedding())\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
    "query = \"smoking policy\"\n",
    "docs = retriever.invoke(query)\n",
    "docs\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "### Self-Querying Retriever for a query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you use the Self Querying Retriever to invoke a query with a filter?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for a Solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "# You might encouter some errors or blank content when run the following code.\n",
    "# It is becasue LLM cannot get the answer at first. Don't worry, re-run it several times you will get the answer.\n",
    "\n",
    "vectordb = Chroma.from_documents(docs, watsonx_embedding())\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm(),\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")\n",
    "\n",
    "# This example specifies a query with filter\n",
    "retriever.invoke(\n",
    "    \"I want to watch a movie directed by Christopher Nolan\"\n",
    ")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kang Wang](https://author.skills.network/instructors/kang_wang)\n",
    "\n",
    "Kang Wang is a Data Scientist in IBM. He is also a PhD Candidate in the University of Waterloo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo)\n",
    "\n",
    "Joseph has a Ph.D. in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{## Change Log}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{|Date (YYYY-MM-DD)|Version|Changed By|Change Description||-|-|-|-||2024-07-29|0.1|Kang Wang|Create the lab|}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "7b245d5a13dda3658f448e990d2ee3f7b0c9eae21542e3ecec8dfce1b522ff5b"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
